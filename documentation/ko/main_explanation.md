# 메인 파이프라인 설명 (`main.py`)

이 파일은 전체 과학 실험을 실행합니다. 데이터 로딩, 모델 학습, 그리고 "제거 연구(Ablation Study)"(뇌 영역을 체계적으로 비활성화하여 결과를 관찰하는 실험)를 연결합니다.

## 1. 데이터 로딩 (Data Loading)

### `load_seed4_session(mat_path, session_idx)`
*   **목표:** 데이터셋에서 제공하는 원본 `.mat` 파일을 읽습니다.
*   **입력:** 한 피험자의 한 세션에 대한 EEG 특징(미분 엔트로피, DE)을 포함하는 파일.
*   **과정:**
    1.  24개의 시행(감정을 유발하는 영화 클립)을 순회합니다.
    2.  `trial_data`는 원래 `(62 채널, 시간, 5 주파수 대역)`의 형태를 가집니다.
    3.  PyTorch 모델은 보통 배치(시간) 차원을 가장 먼저 예상하므로 `(시간, 62, 5)`로 전치(transpose)합니다.
    4.  보여준 영화 클립에 해당하는 레이블 리스트 `y` (0=중립, 1=슬픔, 2=공포, 3=행복)를 생성합니다.
*   **출력:** 모든 EEG 샘플을 포함하는 거대한 배열 `X`와 레이블 `y`.

## 2. 제거 도구 (The Ablation Tool)

### `make_channel_mask(active_indices, ...)`
*   **개념:** 뇌의 일부분을 "끄는(turning off)" 시뮬레이션을 위해 **마스크(Mask)**를 생성합니다.
*   **로직:**
    *   62개의 0으로 구성된 행을 만듭니다: `[0, 0, 0, ... 0]`.
    *   `active_indices`(우리가 유지하고 싶은 채널)를 1로 설정합니다: `[0, 1, 1, ... 0]`.
*   **사용법:** 이 마스크는 모델로 전송됩니다. `models_explanation.md`에서 설명된 바와 같이, 모델은 0을 `-infinity`(음의 무한대)로 대체하여 해당 채널을 효과적으로 침묵시킵니다.

## 3. 학습 도우미 (Training Helpers)

### `train_one_epoch(...)` & `evaluate(...)`
*   표준적인 딥러닝 루프입니다.
*   **핵심 세부사항:** `evaluate`는 `channel_mask`를 허용합니다.
    *   학습 시에는 보통 마스크 없이(mask=None) 모델이 전체 뇌로부터 학습하게 합니다.
    *   제거 연구를 위해 테스트할 때는 특정 채널 없이 모델이 어떻게 실패하는지 확인하기 위해 마스크를 전달합니다.

## 4. 실험 단계 (The Experiment Phases)

스크립트는 5가지 뚜렷한 단계로 실행됩니다.

### 0단계: 데이터 준비 (Data Preparation)
*   15명의 모든 피험자 데이터를 로드합니다.
*   **Z-점수 정규화 (Z-Score Normalization):**
    *   `X = (X - 평균) / 표준편차`
    *   이 과정은 모든 데이터를 대략 -1과 1 사이로 스케일링합니다. 이는 신경망이 안정적으로 학습하는 데 매우 중요합니다.

### 1단계: 하이퍼파라미터 탐색 (교차 검증)
*   **목표:** 테스트 세트를 미리 보지 않고(컨닝하지 않고) 최적의 설정(학습률, 모델 크기 등)을 찾습니다.
*   **방법:**
    *   세션 1과 2의 데이터를 통합합니다.
    *   **5-겹 교차 검증(5-Fold Cross-Validation)**을 사용합니다: 데이터를 5등분 합니다. 4개로 학습하고 1개로 테스트하며, 이를 5번 회전합니다.
    *   이는 "이 구성이 일반적으로 얼마나 좋은지"에 대한 견고한 추정치를 제공합니다.

### 2단계: 피험자별 학습 (Per-Subject Training)
*   **목표:** 15명의 피험자 각각을 위한 개인화된 모델을 학습시킵니다.
*   **데이터 분할:**
    *   **학습:** 세션 1 + 세션 2.
    *   **테스트:** 세션 3.
*   **이유:** EEG는 사람마다 크게 다릅니다. 일반적인 "모두에게 맞는" 모델은 종종 실패합니다. 우리는 15개의 별도 모델을 학습시킵니다.
*   **조기 종료 (Early Stopping):** 모델이 테스트 세트에서 성능 향상을 멈추면, "과적합(Overfitting)"(노이즈를 암기하는 것)을 방지하기 위해 학습을 중단합니다.

### 3단계: 중요도 추출 (Extracting Importance)
*   **목표:** 학습된 모델에게 묻습니다: "어떤 채널이 유용했습니까?"
*   **방법:**
    *   테스트 데이터를 모델에 통과시킵니다.
    *   모델로부터 `alpha`(어텐션 가중치)를 수집합니다.
    *   이를 시간에 대해 평균냅니다.
    *   **전체 순위 (Grand Ranking):** 15명 피험자 전체의 중요도를 평균내어 보편적으로 중요한 뇌 영역을 찾습니다.

### 4단계: 전체 제거 연구 (Full Ablation Study - 핵심 실험)
이제 `run_full_ablation_study`를 사용하여 과학적 가설들을 테스트합니다.

#### A. 영역 필요성 (Region Ablation)
*   **질문:** "전두엽(Frontal Lobe)은 필수적인가?"
*   **행동:**
    1.  **유지 (Keep Only):** 전두엽 채널을 *제외한* 모든 것을 마스킹합니다. 정확도를 테스트합니다.
    2.  **제거 (Remove):** 전두엽 채널*만* 마스킹합니다. 정확도를 테스트합니다.
*   전두엽, 측두엽, 두정엽, 후두엽 등에 대해 이를 수행합니다.

#### B. 반구 비대칭성 (Hemisphere Asymmetry)
*   **질문:** "좌뇌가 우뇌보다 감정적인가?"
*   **행동:** 좌뇌 채널만 유지 vs 우뇌 채널만 유지.

#### C. 몽타주 분석 (상용 헤드셋)
*   **질문:** "저렴한 4채널 헤드셋(Muse)으로 감정을 감지할 수 있을까?"
*   **행동:** Muse 헤드밴드에서 사용하는 4개 채널(TP9, AF7, AF8, TP10)을 제외한 모든 채널을 마스킹합니다. 전체 62채널 캡과 정확도를 비교합니다.

#### D. 점진적 제거 (The "Curve")
*   **질문:** "우리는 *정말로* 몇 개의 채널이 필요한가? 10개? 20개?"
*   **전략 1 (스마트):** 가장 중요한 상위 5개 채널(3단계에서 얻은)을 유지하고, 그 다음 상위 10개, 15개... 순으로 늘려갑니다.
*   **전략 2 (무작위):** 무작위 5개 채널, 무작위 10개... 를 유지합니다.
*   **예상:** "스마트" 곡선이 "무작위" 곡선보다 훨씬 빠르게 상승해야 합니다. 이는 우리의 어텐션 메커니즘이 실제로 의미 있는 신호를 찾았음을 증명합니다.

### 5단계: 시각화 (Visualization)
*   결과를 시각화하기 위해 PDF를 생성합니다:
    *   `topomap_attention.pdf`: 뇌의 핫스팟(중요 부위)을 보여주는 열 지도(heatmap).
    *   `progressive_ablation.pdf`: 채널 수 대 정확도를 보여주는 선 그래프.
    *   `region_ablation.pdf`: 뇌 영역들을 비교하는 막대 그래프.

## 5. 통계적 검정 (Statistical Tests)
*   **윌콕슨 부호 순위 검정 (Wilcoxon Signed-Rank Test)**을 사용합니다.
*   **이유:** 결과가 단순히 운이 아니었음을 증명하기 위함입니다.
*   "전체 캡" vs "Muse 헤드셋"에 대한 15명 피험자의 정확도 목록을 비교합니다.
*   만약 p < 0.05라면, 그 차이는 통계적으로 유의미합니다.
